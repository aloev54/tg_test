#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
site_to_telegram.py ‚Äî –†—É–ª–Å–∂–∫–∞-—Å—Ç–∞–π–ª (—Ñ–æ—Ç–æ –æ—Ç–¥–µ–ª—å–Ω–æ, —Ç–µ–∫—Å—Ç –æ—Ç–¥–µ–ª—å–Ω–æ, LLM-—Å—Ç–∏–ª–∏–∑–∞—Ü–∏—è –±–µ–∑ –ª–∏–º–∏—Ç–∞ 1024)

–§–æ—Ä–º–∞—Ç –ø–æ—Å—Ç–∞ (TEXT message):
üöó <b>–ó–∞–≥–æ–ª–æ–≤–æ–∫</b>

–ò–Ω—Ç—Ä–∏–≥—É—é—â–µ–µ –≤—Å—Ç—É–ø–ª–µ–Ω–∏–µ (1‚Äì2 —Å—Ç—Ä–æ–∫–∏).

1Ô∏è‚É£ ... (—Ñ–∞–∫—Ç—ã/—Ü–∏—Ñ—Ä—ã/–¥–µ—Ç–∞–ª–∏ —Å —ç–º–æ—Ü–∏–µ–π; –¥–æ–ø—É—Å–∫–∞–µ—Ç—Å—è <b>–∂–∏—Ä–Ω—ã–π</b>, <i>–∫—É—Ä—Å–∏–≤</i>)
2Ô∏è‚É£ ...
3Ô∏è‚É£ ...

–ö–æ—Ä–æ—Ç–∫–∞—è —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –º—ã—Å–ª—å.

üèéÔ∏è <a href="https://t.me/drive_hedgehog">–†—É–ª–Å–∂–∫–∞</a>

‚Äî –±–µ–∑ —Å—Å—ã–ª–æ–∫ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
‚Äî –±–µ–∑ –æ–±—ã—á–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤ (-, ‚Ä¢)
‚Äî —ç–º–æ–¥–∑–∏-–Ω—É–º–µ—Ä–∞—Ü–∏—è 1Ô∏è‚É£ 2Ô∏è‚É£ 3Ô∏è‚É£ ‚Äî —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–π, –Ω–µ –ø–µ—Ä–µ–¥ –∫–∞–∂–¥—ã–º –∞–±–∑–∞—Ü–µ–º
‚Äî —Ñ–æ—Ç–æ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –û–¢–î–ï–õ–¨–ù–´–ú —Å–æ–æ–±—â–µ–Ω–∏–µ–º –±–µ–∑ –ø–æ–¥–ø–∏—Å–∏
"""

import argparse, html, json, os, re, sys, time
from dataclasses import dataclass
from typing import List, Optional
from urllib.parse import urljoin

import requests
from bs4 import BeautifulSoup

DEFAULT_UA = "Mozilla/5.0 (compatible; rul-ezhka/2.1)"
TELEGRAM_API_BASE = "https://api.telegram.org"
STATE_FILE = "autonews_seen_nb.json"

ARTICLE_SELECTORS = [
    "article","[itemprop='articleBody']",".article__body",".js-mediator-article",".article",
]
DROP_SELECTORS = [
    "script","style","noscript",
    "[class*='advert']","[class*='ad-']","[class*='ad_']","[id*='ad']",
    "[class*='banner']","[class*='promo']",
    "[class*='subscribe']","[class*='subscription']",
    "[class*='breadcrumbs']","[class*='share']","[class*='social']",
    "[class*='tags']","[class*='related']","[class*='widget']",
    "figure figcaption",".photo-credit",".copyright",
]
DROP_PHRASES = [
    "—Ä–µ–∫–ª–∞–º–∞","–ø–æ–¥–ø–∏—Å","—á–∏—Ç–∞–π—Ç–µ —Ç–∞–∫–∂–µ","—Å–º–æ—Ç—Ä–∏—Ç–µ —Ç–∞–∫–∂–µ","–Ω–∞—à —Ç–µ–ª–µ–≥—Ä–∞–º",
    "–ø—Ä–æ–º–æ–∫–æ–¥","–ø–æ–¥—Ä–æ–±–Ω–µ–µ","—Ä–µ–∫–ª–∞–º",
]

EMOJI_MAP = [
    (["–¥—Ç–ø","–∞–≤–∞—Ä","—Å—Ç–æ–ª–∫–Ω–æ–≤"],"üö®"),
    (["—à—Ç—Ä–∞—Ñ","–Ω–∞–ª–æ–≥","–ø–æ—à–ª–∏–Ω","—É—Ç–∏–ª—å—Å–±–æ—Ä"],"üí∏"),
    (["—ç–ª–µ–∫—Ç—Ä–æ","ev","–±–∞—Ç–∞—Ä","–∑–∞—Ä—è–¥"],"‚ö°"),
    (["–±–µ–Ω–∑–∏–Ω","–¥–∏–∑–µ–ª","—Ç–æ–ø–ª–∏–≤"],"‚õΩ"),
    (["—Ç—Ä–∞—Å—Å","–¥–æ—Ä–æ–≥","—Ä–µ–º–æ–Ω—Ç","–º–æ—Å—Ç"],"üõ£Ô∏è"),
    (["–≥–æ–Ω–∫","—Å–ø–æ—Ä—Ç","—Ä–∞–ª–ª–∏","—Ç—Ä–µ–∫"],"üèÅ"),
]

@dataclass
class Item:
    title: str
    url: str
    image: Optional[str]
    paras: List[str]

# ---------------- Helpers ----------------
def fetch_html(url:str)->str:
    r=requests.get(url,headers={"User-Agent":DEFAULT_UA},timeout=25)
    r.raise_for_status()
    return r.text

def normalize_title(title:str)->str:
    t=title.strip()
    patterns=[
        r"\s*[-‚Äì‚Äî|:]{1,3}\s*(–ì–ª–∞–≤–Ω–æ–µ\s*)?::?\s*Autonews(?:\.ru)?\s*$",
        r"\s*[-‚Äì‚Äî|:]{1,3}\s*Autonews(?:\.ru)?\s*$",
        r"\s*\|\s*(–ì–ª–∞–≤–Ω–æ–µ|–ù–æ–≤–æ—Å—Ç–∏)\s*$",
        r"\s*::\s*(–ì–ª–∞–≤–Ω–æ–µ|–ù–æ–≤–æ—Å—Ç–∏)\s*$",
    ]
    for p in patterns:
        t=re.sub(p,"",t,flags=re.IGNORECASE)
    t=re.split(r"\s[-‚Äì‚Äî|:]{1,3}\s",t)[0].strip() or t
    return t

def extract_listing_links(html_text:str,base_url:Optional[str],selector:str,limit:int)->List[str]:
    soup=BeautifulSoup(html_text,"html.parser")
    nodes=soup.select(selector)[:limit]
    out=[]
    for n in nodes:
        a=n if n.name=="a" else n.find("a")
        if a and a.get("href"):
            href=urljoin(base_url,a["href"]) if base_url else a["href"]
            if href not in out:
                out.append(href)
    return out

def is_junk(t:str)->bool:
    lt=t.lower()
    if len(lt)<40: return True
    return any(p in lt for p in DROP_PHRASES)

def parse_article(url:str,base_url:Optional[str])->Item:
    soup=BeautifulSoup(fetch_html(url),"html.parser")

    # title
    t=soup.find("meta",property="og:title")
    title=t["content"].strip() if t and t.get("content") else (soup.title.string.strip() if soup.title else url)
    title=normalize_title(title)

    # image
    im=soup.find("meta",property="og:image")
    image=im["content"].strip() if im and im.get("content") else None
    if image and base_url:
        image=urljoin(base_url,image)

    # body root
    root=None
    for sel in ARTICLE_SELECTORS:
        node=soup.select_one(sel)
        if node:
            root=node;break
    if not root: root=soup

    # drop junk nodes (—É—Å—Ç–æ–π—á–∏–≤–æ –∫ –æ—à–∏–±–∫–∞–º —Å–µ–ª–µ–∫—Ç–æ—Ä–∞)
    for sel in DROP_SELECTORS:
        try:
            for node in root.select(sel):
                node.decompose()
        except Exception:
            continue

    paras=[]
    for p in root.find_all("p"):
        txt=re.sub(r"\s+"," ",p.get_text(" ",strip=True))
        if txt and not is_junk(txt):
            paras.append(txt)

    if not paras:
        d=soup.find("meta",property="og:description")
        if d and d.get("content"):
            paras=[d["content"].strip()]

    return Item(title=title,url=url,image=image,paras=paras[:14])

def choose_emoji(title:str,text:str)->str:
    s=(title+" "+text).lower()
    for keys,e in EMOJI_MAP:
        if any(k in s for k in keys):
            return e
    return "üöó"

def join_text(paras:List[str],limit:int=2000)->str:
    out,cur=[],0
    for p in paras:
        if cur+len(p)>limit: break
        out.append(p);cur+=len(p)+1
        if len(out)>=8: break
    return " ".join(out)

# ---------------- LLM ----------------
def llm_style_post(title:str,text:str)->Optional[str]:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç (–Ω–µ caption!) –ø–æ —Ç–≤–æ–∏–º –ø—Ä–∞–≤–∏–ª–∞–º, –±–µ–∑ –ª–∏–º–∏—Ç–∞ 1024.
    –î–æ–ø—É—Å–∫–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ <b> –∏ <i>.
    """
    api=os.getenv("OPENAI_API_KEY","").strip()
    if not api:
        return None
    import json,urllib.request as urlreq
    sys_prompt=(
        "–°–æ–∑–¥–∞–π –ø–æ—Å—Ç –¥–ª—è Telegram-–∫–∞–Ω–∞–ª–∞ –ø—Ä–æ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏. –ü–∏—à–∏ –∂–∏–≤–æ –∏ —Å —É–≤–ª–µ—á–µ–Ω–∏–µ–º ‚Äî –∫–∞–∫ –∞–≤—Ç–æ–ª—é–±–∏—Ç–µ–ª—å, –∞ –Ω–µ –∂—É—Ä–Ω–∞–ª–∏—Å—Ç. "
        "–°—Ç—Ä—É–∫—Ç—É—Ä–∞: 1) –∫–æ—Ä–æ—Ç–∫–æ–µ –∏–Ω—Ç—Ä–∏–≥—É—é—â–µ–µ –≤—Å—Ç—É–ø–ª–µ–Ω–∏–µ (1‚Äì2 —Å—Ç—Ä–æ–∫–∏), 2) –æ—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å —Å —Ñ–∞–∫—Ç–∞–º–∏, —Ü–∏—Ñ—Ä–∞–º–∏ –∏ –¥–µ—Ç–∞–ª—è–º–∏, "
        "3) –µ—Å–ª–∏ —É–º–µ—Å—Ç–Ω–æ ‚Äî –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–µ —Å —ç–º–æ–¥–∑–∏-–Ω—É–º–µ—Ä–∞—Ü–∏–µ–π 1Ô∏è‚É£ 2Ô∏è‚É£ 3Ô∏è‚É£ (–∏—Å–ø–æ–ª—å–∑—É–π –Ω—É–º–µ—Ä–∞—Ü–∏—é –¢–û–õ–¨–ö–û –¥–ª—è —Å–ø–∏—Å–∫–æ–≤), "
        "4) –∫–æ—Ä–æ—Ç–∫–∞—è —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –º—ã—Å–ª—å/—Å–æ–≤–µ—Ç. "
        "–î–æ–±–∞–≤–ª—è–π –Ω–µ–º–Ω–æ–≥–æ —ç–º–æ—Ü–∏–π, —Å—Ä–∞–≤–Ω–µ–Ω–∏–π –∏–ª–∏ –º–µ—Ç–∞—Ñ–æ—Ä. "
        "–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: <b>–∂–∏—Ä–Ω—ã–π</b> ‚Äî –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∏ –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤; <i>–∫—É—Ä—Å–∏–≤</i> ‚Äî –¥–ª—è –¥–µ—Ç–∞–ª–µ–π –∏ —É—Ç–æ—á–Ω–µ–Ω–∏–π. "
        "–ù–ï –∏—Å–ø–æ–ª—å–∑—É–π –æ–±—ã—á–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã '-' –∏–ª–∏ '‚Ä¢'. –ù–ï –≤—Å—Ç–∞–≤–ª—è–π —Å—Å—ã–ª–∫–∏ –∏ –ø—Ä–∏–∑—ã–≤—ã. "
        "–í–µ—Ä–Ω–∏ —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –ø–æ—Å—Ç–æ—Ä–æ–Ω–Ω–∏—Ö HTML-—Ç–µ–≥–æ–≤, –∫—Ä–æ–º–µ <b> –∏ <i>."
    )
    user_prompt = f"–ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}\n\n–û—Å–Ω–æ–≤–∞ —Ç–µ–∫—Å—Ç–∞ (–æ—á–∏—â–µ–Ω–Ω—ã–µ –∞–±–∑–∞—Ü—ã):\n{text}"
    payload={
        "model":"gpt-4o-mini",
        "temperature":0.35,
        "messages":[
            {"role":"system","content":sys_prompt},
            {"role":"user","content":user_prompt}
        ]
    }
    req=urlreq.Request(
        "https://api.openai.com/v1/chat/completions",
        data=json.dumps(payload).encode("utf-8"),
        headers={"Authorization":f"Bearer {api}","Content-Type":"application/json"},
        method="POST",
    )
    try:
        with urlreq.urlopen(req,timeout=30) as resp:
            d=json.loads(resp.read().decode("utf-8"))
        t=d["choices"][0]["message"]["content"].strip().replace("\r","")
        # –†–∞–∑—Ä–µ—à–∞–µ–º —Ç–æ–ª—å–∫–æ <b>/<i>
        t=html.escape(t).replace("&lt;b&gt;","<b>").replace("&lt;/b&gt;","</b>").replace("&lt;i&gt;","<i>").replace("&lt;/i&gt;","</i>")
        # –ù–∞ –≤—Å—è–∫–∏–π: —É–±–µ—Ä—ë–º —Å–ª—É—á–∞–π–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫
        t=re.sub(r"^[\-\*‚Ä¢]\s+","",t,flags=re.M)
        return t
    except Exception:
        return None

# ---------------- Telegram ----------------
def tg_send_photo(token:str,chat_id:str,photo_url:Optional[str],thread_id:Optional[int]=None)->Optional[int]:
    if not photo_url:
        return None
    data={"chat_id":chat_id,"photo":photo_url}
    if thread_id is not None:
        data["message_thread_id"]=thread_id
    r=requests.post(f"{TELEGRAM_API_BASE}/bot{token}/sendPhoto",data=data,timeout=30)
    r.raise_for_status()
    return r.json()["result"]["message_id"]

def tg_send_text(token:str,chat_id:str,text_html:str,thread_id:Optional[int]=None)->int:
    data={"chat_id":chat_id,"text":text_html,"parse_mode":"HTML","disable_web_page_preview":True}
    if thread_id is not None:
        data["message_thread_id"]=thread_id
    r=requests.post(f"{TELEGRAM_API_BASE}/bot{token}/sendMessage",data=data,timeout=30)
    r.raise_for_status()
    return r.json()["result"]["message_id"]

def tg_copy(token:str,from_chat_id:str,message_id:int,to_chat_id:str)->None:
    requests.post(f"{TELEGRAM_API_BASE}/bot{token}/copyMessage",
                  data={"from_chat_id":from_chat_id,"message_id":message_id,"chat_id":to_chat_id},
                  timeout=20)

# ---------------- Main ----------------
def main():
    ap=argparse.ArgumentParser()
    ap.add_argument("--url",required=True)
    ap.add_argument("--item-selector",required=True)
    ap.add_argument("--limit",type=int,default=1)  # –±–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω—é—é
    ap.add_argument("--base-url")
    ap.add_argument("--state",default=STATE_FILE)
    ap.add_argument("--with-photo",action="store_true")
    ap.add_argument("--thread-id",type=int)
    ap.add_argument("--copy-to-chat-id")
    a=ap.parse_args()

    token=os.getenv("TELEGRAM_BOT_TOKEN","").strip()
    chat=os.getenv("TELEGRAM_CHAT_ID","").strip()
    if not token or not chat:
        sys.exit("Need TELEGRAM_BOT_TOKEN and TELEGRAM_CHAT_ID")

    # –±–µ–∑–æ–ø–∞—Å–Ω–æ —á–∏—Ç–∞–µ–º thread_id
    env_th=os.getenv("TELEGRAM_THREAD_ID","").strip()
    if a.thread_id is not None:
        th=a.thread_id
    elif env_th.isdigit():
        th=int(env_th)
    else:
        th=None

    copy=os.getenv("TELEGRAM_COPY_TO_CHAT_ID","").strip() or (a.copy_to_chat_id or "").strip()

    # state
    seen=set()
    if os.path.exists(a.state):
        try:
            with open(a.state,"r",encoding="utf-8") as f:
                seen=set(json.load(f))
        except Exception:
            seen=set()

    # —Å—Å—ã–ª–∫–∏
    listing=fetch_html(a.url)
    links=extract_listing_links(listing,a.base_url,a.item_selector,a.limit)

    for link in links:
        if link in seen: continue
        item=parse_article(link,a.base_url)
        merged=join_text(item.paras,limit=2000)

        # 1) –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–æ—Ç–æ (–µ—Å–ª–∏ –µ—Å—Ç—å –∏ –∑–∞–ø—Ä–æ—à–µ–Ω–æ)
        if a.with_photo and item.image:
            tg_send_photo(token,chat,item.image,th)

        # 2) –≥–æ—Ç–æ–≤–∏–º —Ç–µ–∫—Å—Ç LLM (–∏–ª–∏ —Ñ–æ–ª–±—ç–∫)
        body=llm_style_post(item.title,merged)
        if not body:
            # –ø—Ä–æ—Å—Ç–æ–π —Ñ–æ–ª–±—ç–∫: –∏–Ω—Ç—Ä–æ + 1-3 –ø—É–Ω–∫—Ç–∞ 1Ô∏è‚É£.. –±–µ–∑ ¬´-¬ª/¬´‚Ä¢¬ª
            sents=re.split(r"(?<=[.!?‚Ä¶])\s+", merged)
            intro=" ".join(sents[:2]).strip()
            pts=[s for s in sents[2:] if 50<=len(s)<=220][:3]
            nums=["1Ô∏è‚É£","2Ô∏è‚É£","3Ô∏è‚É£"]
            body = intro + ("\n\n" if intro else "")
            for i,p in enumerate(pts):
                body += f"{nums[i]} {p}\n"
            body=body.strip()

        emoji=choose_emoji(item.title,merged)
        text = f"{emoji} <b>{html.escape(item.title)}</b>\n\n{body}\n\nüèéÔ∏è <a href=\"https://t.me/drive_hedgehog\">–†—É–ª–Å–∂–∫–∞</a>"

        # 3) –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
        msg_id = tg_send_text(token,chat,text,th)

        # 4) –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∫–æ–ø–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –≤ –∫–∞–Ω–∞–ª
        if copy:
            tg_copy(token,chat,msg_id,copy)

        seen.add(link)
        with open(a.state,"w",encoding="utf-8") as f:
            json.dump(sorted(list(seen)),f,ensure_ascii=False,indent=2)

        time.sleep(1.0)

    print("Done.")

if __name__=="__main__":
    main()
