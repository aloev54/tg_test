#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
site_to_telegram.py ‚Äî –†—É–ª–Å–∂–∫–∞-—Å—Ç–∞–π–ª (LLM + –∞–Ω—Ç–∏-—Ä–µ–∫–ª–∞–º–∞ + –Ω—É–º–µ—Ä–∞—Ü–∏—è —ç–º–æ–¥–∑–∏)

–§–æ—Ä–º–∞—Ç –ø–æ—Å—Ç–∞:
üöó **–ó–∞–≥–æ–ª–æ–≤–æ–∫**
–ò–Ω—Ç—Ä–∏–≥—É—é—â–µ–µ –≤—Å—Ç—É–ø–ª–µ–Ω–∏–µ (1‚Äì2 —Å—Ç—Ä–æ–∫–∏).
1Ô∏è‚É£ ... (—Ñ–∞–∫—Ç/–¥–µ—Ç–∞–ª—å, –º–æ–∂–Ω–æ —Å *–∫—É—Ä—Å–∏–≤–æ–º* –∏ **–∂–∏—Ä–Ω—ã–º–∏ –∞–∫—Ü–µ–Ω—Ç–∞–º–∏**)
2Ô∏è‚É£ ...
3Ô∏è‚É£ ...
–ö–æ—Ä–æ—Ç–∫–∞—è —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –º—ã—Å–ª—å/—Å–æ–≤–µ—Ç (1 —Å—Ç—Ä–æ–∫–∞).
üèéÔ∏è –†—É–ª–Å–∂–∫–∞ (https://t.me/drive_hedgehog)

‚Äî –±–µ–∑ —Å—Å—ã–ª–æ–∫ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫
‚Äî –±–µ–∑ –æ–±—ã—á–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤/—Ç–æ—á–µ–∫-‚Ä¢ (—Ç–æ–ª—å–∫–æ 1Ô∏è‚É£ 2Ô∏è‚É£ 3Ô∏è‚É£ ...)
‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –∫–∞–∫ photo+caption (HTML), —Ä–∞–∑—Ä–µ—à–µ–Ω—ã <b> –∏ <i>
‚Äî –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Ç–µ–º—ã (message_thread_id) –∏ –∫–æ–ø–∏–∏ –≤ –∫–∞–Ω–∞–ª (copyMessage)
"""

import argparse
import html
import json
import os
import re
import sys
import time
from dataclasses import dataclass
from typing import List, Optional
from urllib.parse import urljoin

import requests
from bs4 import BeautifulSoup

DEFAULT_UA = "Mozilla/5.0 (compatible; rul-ezhka/1.8)"
TELEGRAM_API_BASE = "https://api.telegram.org"
STATE_FILE = "autonews_seen_nb.json"

ARTICLE_SELECTORS = [
    "article",
    "[itemprop='articleBody']",
    ".article__body",
    ".js-mediator-article",
    ".article",
]
DROP_SELECTORS = [
    "script", "style", "noscript",
    "[class*='advert']", "[class*='ad-']", "[class*='ad_']", "[id*='ad']",
    "[class*='banner']", "[class*='promo']",
    "[class*='subscribe']", "[class*='subscription']",
    "[class*='breadcrumbs']", "[class*='share']", "[class*='social']",
    "[class*='tags']", "[class*='related']", "[class*='widget']",
    "figure figcaption", ".photo-credit", ".copyright",
]
DROP_PHRASES = [
    "—Ä–µ–∫–ª–∞–º–∞", "–ø–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å", "–ø–æ–¥–ø–∏—à–∏—Ç–µ—Å—å", "–ø–æ–¥–ø–∏—Å–∫–∞",
    "—á–∏—Ç–∞–π—Ç–µ —Ç–∞–∫–∂–µ", "—Å–º–æ—Ç—Ä–∏—Ç–µ —Ç–∞–∫–∂–µ", "—É–∑–Ω–∞—Ç—å –±–æ–ª—å—à–µ", "—Ä–∞—Å—Å—ã–ª–∫–∞",
    "–Ω–∞—à —Ç–µ–ª–µ–≥—Ä–∞–º", "–Ω–∞—à telegram", "instagram", "vk.com", "–≤–∫–æ–Ω—Ç–∞–∫—Ç–µ",
    "—Å–∫–∞—á–∞–π—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ", "–ø—Ä–∏—Å–æ–µ–¥–∏–Ω—è–π—Ç–µ—Å—å –∫", "–ø—Ä–æ–º–æ–∫–æ–¥",
]

EMOJI_MAP = [
    (["–¥—Ç–ø", "–∞–≤–∞—Ä", "—Å—Ç–æ–ª–∫–Ω–æ–≤"], "üö®"),
    (["—à—Ç—Ä–∞—Ñ", "–Ω–∞–ª–æ–≥", "–ø–æ—à–ª–∏–Ω", "—É—Ç–∏–ª—å—Å–±–æ—Ä"], "üí∏"),
    (["—ç–ª–µ–∫—Ç—Ä–æ", "ev", "–±–∞—Ç–∞—Ä", "–∑–∞—Ä—è–¥"], "‚ö°"),
    (["–±–µ–Ω–∑–∏–Ω", "–¥–∏–∑–µ–ª", "—Ç–æ–ø–ª–∏–≤"], "‚õΩ"),
    (["—Ç—Ä–∞—Å—Å", "–¥–æ—Ä–æ–≥", "—Ä–µ–º–æ–Ω—Ç", "–º–æ—Å—Ç"], "üõ£Ô∏è"),
    (["—Ç–µ—Å—Ç", "–æ–±–∑–æ—Ä", "—Ç–µ—Å—Ç-–¥—Ä–∞–π–≤"], "üß™"),
    (["–≥–æ–Ω–∫", "—Ç—Ä–µ–∫", "—Ä–∞–ª–ª–∏", "—Å–ø–æ—Ä—Ç"], "üèÅ"),
]

@dataclass
class Item:
    title: str
    url: str
    image: Optional[str]
    paras: List[str]  # –æ—á–∏—â–µ–Ω–Ω—ã–µ –∞–±–∑–∞—Ü—ã —Å—Ç–∞—Ç—å–∏

# ---------------- Core helpers ----------------
def fetch_html(url: str) -> str:
    r = requests.get(url, headers={"User-Agent": DEFAULT_UA}, timeout=25)
    r.raise_for_status()
    return r.text

def extract_listing_links(list_html: str, base_url: Optional[str], selector: str, limit: int) -> List[str]:
    soup = BeautifulSoup(list_html, "html.parser")
    nodes = soup.select(selector)[:limit]
    links = []
    for n in nodes:
        a = n if n.name == "a" else n.find("a")
        if a and a.get("href"):
            links.append(urljoin(base_url, a["href"]) if base_url else a["href"])
    # dedupe preserve order
    seen, out = set(), []
    for u in links:
        if u not in seen:
            out.append(u); seen.add(u)
    return out

def normalize_title(title: str) -> str:
    """–°—Ä–µ–∑–∞–µ–º —Ö–≤–æ—Å—Ç—ã —Ç–∏–ø–∞ '–ì–ª–∞–≤–Ω–æ–µ :: Autonews', '‚Äî Autonews', '| Autonews' –∏ —Ç.–ø."""
    t = title.strip()
    patterns = [
        r"\s*[-‚Äì‚Äî|:]{1,3}\s*(–ì–ª–∞–≤–Ω–æ–µ\s*)?::?\s*Autonews(?:\.ru)?\s*$",
        r"\s*[-‚Äì‚Äî|:]{1,3}\s*Autonews(?:\.ru)?\s*$",
        r"\s*\|\s*(–ì–ª–∞–≤–Ω–æ–µ|–ù–æ–≤–æ—Å—Ç–∏)\s*$",
        r"\s*::\s*(–ì–ª–∞–≤–Ω–æ–µ|–ù–æ–≤–æ—Å—Ç–∏)\s*$",
    ]
    for p in patterns:
        t = re.sub(p, "", t, flags=re.IGNORECASE)
    t = re.split(r"\s[-‚Äì‚Äî|:]{1,3}\s", t)[0].strip() or t
    return t

def clean_text(t: str) -> str:
    t = re.sub(r"\s+", " ", t).strip()
    t = re.sub(r"–ß–∏—Ç–∞–π—Ç–µ —Ç–∞–∫–∂–µ.*$", "", t, flags=re.I)
    return t

def is_junk(t: str) -> bool:
    lt = t.lower()
    if len(lt) < 40: return True
    return any(p in lt for p in DROP_PHRASES)

def parse_article(url: str, base_url: Optional[str]) -> Item:
    html_text = fetch_html(url)
    soup = BeautifulSoup(html_text, "html.parser")

    # title
    title = None
    t = soup.find("meta", property="og:title")
    if t and t.get("content"):
        title = t["content"].strip()
    if not title and soup.title and soup.title.string:
        title = soup.title.string.strip()
    title = normalize_title(title or url)

    # image
    image = None
    im = soup.find("meta", property="og:image")
    if im and im.get("content"):
        image = im["content"].strip()
    if image and base_url:
        image = urljoin(base_url, image)

    # body root
    root = None
    for sel in ARTICLE_SELECTORS:
        node = soup.select_one(sel)
        if node:
            root = node; break
    if not root: root = soup

    # drop junk nodes (—É—Å—Ç–æ–π—á–∏–≤–æ –∫ –æ—à–∏–±–∫–∞–º —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤)
    for sel in DROP_SELECTORS:
        try:
            for node in root.select(sel):
                node.decompose()
        except Exception:
            continue

    # paragraphs
    paras = []
    for p in root.find_all("p"):
        txt = clean_text(p.get_text(" ", strip=True))
        if txt and not is_junk(txt):
            paras.append(txt)

    if not paras:
        desc = soup.find("meta", property="og:description")
        if desc and desc.get("content"):
            paras = [desc["content"].strip()]

    return Item(title=title, url=url, image=image, paras=paras[:14])

def choose_emoji(title: str, text: str) -> str:
    s = (title + " " + text).lower()
    for keys, e in EMOJI_MAP:
        if any(k in s for k in keys): return e
    return "üöó"

def join_for_llm(paras: List[str], target=900) -> str:
    out, cur = [], 0
    for p in paras:
        if cur + len(p) > target and out: break
        out.append(p); cur += len(p) + 1
        if len(out) >= 6: break
    return " ".join(out)

# ---------------- LLM style (preferred) ----------------
def llm_style_post(title: str, merged_text: str) -> Optional[str]:
    """
    –¢—Ä–µ–±—É–µ–º —É –º–æ–¥–µ–ª–∏:
    - 1‚Äì2 —Å—Ç—Ä–æ–∫–∏ –∏–Ω—Ç—Ä–∏–≥—É—é—â–µ–≥–æ –≤—Å—Ç—É–ø–ª–µ–Ω–∏—è (–±–µ–∑ –æ–±—ã—á–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤)
    - –∑–∞—Ç–µ–º 3‚Äì5 –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã—Ö –±–ª–æ–∫–æ–≤ —Å —ç–º–æ–¥–∑–∏ 1Ô∏è‚É£ 2Ô∏è‚É£ 3Ô∏è‚É£ 4Ô∏è‚É£ 5Ô∏è‚É£ (–ù–ï '-', –Ω–µ '‚Ä¢')
    - **–∂–∏—Ä–Ω—ã–π** –¥–ª—è –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤, <i>–∫—É—Ä—Å–∏–≤</i> –¥–ª—è 4‚Äì8 –¥–µ—Ç–∞–ª–µ–π
    - –±–µ–∑ —Å—Å—ã–ª–æ–∫ –∏ –ø—Ä–∏–∑—ã–≤–æ–≤
    - –±–µ–∑ –ø–æ—Å—Ç–æ—Ä–æ–Ω–Ω–∏—Ö HTML, –∫—Ä–æ–º–µ <b> –∏ <i>
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º HTML-—Å—Ç—Ä–æ–∫—É (—Ç–æ–ª—å–∫–æ <b> –∏ <i> –¥–æ–ø—É—Å—Ç–∏–º—ã).
    """
    api_key = os.getenv("OPENAI_API_KEY", "").strip()
    if not api_key:
        return None
    try:
        import json as _json, urllib.request as _url
        sys_prompt = (
            "–¢—ã –ø–∏—à–µ—à—å –ø–æ—Å—Ç –¥–ª—è –∞–≤—Ç–æ–∫–∞–Ω–∞–ª–∞. –°—Ç–∏–ª—å: –∂–∏–≤–æ, —Ü–µ–ø–ª—è—é—â–µ, –∫–∞–∫ —É–≤–ª–µ—á—ë–Ω–Ω—ã–π –∞–≤—Ç–æ–ª—é–±–∏—Ç–µ–ª—å. "
            "–°–Ω–∞—á–∞–ª–∞ –¥–∞–π 1‚Äì2 —Å—Ç—Ä–æ–∫–∏ –∏–Ω—Ç—Ä–∏–≥—É—é—â–µ–≥–æ –≤—Å—Ç—É–ø–ª–µ–Ω–∏—è. –ü–æ—Ç–æ–º 3‚Äì5 –ø—Ä–æ–Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã—Ö –±–ª–æ–∫–æ–≤ —Å —ç–º–æ–¥–∑–∏ "
            "1Ô∏è‚É£ 2Ô∏è‚É£ 3Ô∏è‚É£ 4Ô∏è‚É£ 5Ô∏è‚É£. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π '-' –∏–ª–∏ '‚Ä¢'. –í –∫–∞–∂–¥–æ–º –±–ª–æ–∫–µ –¥–æ–±–∞–≤–ª—è–π —Ü–∏—Ñ—Ä—ã/—Ñ–∞–∫—Ç—ã/–¥–µ—Ç–∞–ª–∏, "
            "–Ω–µ–º–Ω–æ–≥–æ —ç–º–æ—Ü–∏–π –∏–ª–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è. –ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã –≤—ã–¥–µ–ª—è–π <b>–∂–∏—Ä–Ω—ã–º</b>, –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ –¥–µ—Ç–∞–ª–∏ ‚Äî <i>–∫—É—Ä—Å–∏–≤–æ–º</i> "
            "(–≤ —Å—É–º–º–µ 4‚Äì8 –∫—É—Ä—Å–∏–≤–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤). –ù–µ –≤—Å—Ç–∞–≤–ª—è–π —Å—Å—ã–ª–∫–∏ –∏ –ø—Ä–∏–∑—ã–≤—ã. –í–µ—Ä–Ω–∏ —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –ª–∏—à–Ω–∏—Ö —Ç–µ–≥–æ–≤, "
            "–∫—Ä–æ–º–µ <b> –∏ <i>. –ó–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–µ –ø–∏—à–∏ ‚Äî —Ç–æ–ª—å–∫–æ —Ç–µ–ª–æ."
        )
        user_prompt = f"–ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}\n\n–¢–µ–∫—Å—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏:\n{merged_text}"
        payload = {
            "model": "gpt-4o-mini",
            "temperature": 0.35,
            "messages": [
                {"role": "system", "content": sys_prompt},
                {"role": "user", "content": user_prompt},
            ]
        }
        req = _url.Request(
            "https://api.openai.com/v1/chat/completions",
            data=_json.dumps(payload).encode("utf-8"),
            headers={"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"},
            method="POST",
        )
        with _url.urlopen(req, timeout=25) as resp:
            data = _json.loads(resp.read().decode("utf-8"))
        t = data["choices"][0]["message"]["content"].strip().replace("\r", "")
        # –†–∞–∑—Ä–µ—à–∞–µ–º —Ç–æ–ª—å–∫–æ <b> –∏ <i>
        t = html.escape(t).replace("&lt;b&gt;","<b>").replace("&lt;/b&gt;","</b>").replace("&lt;i&gt;","<i>").replace("&lt;/i&gt;","</i>")
        # –£–±–µ—Ä—ë–º —Å–ª—É—á–∞–π–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫, –µ—Å–ª–∏ –≤–¥—Ä—É–≥
        t = re.sub(r"^[\-\*‚Ä¢]\s+", "", t, flags=re.M)
        return t
    except Exception:
        return None

# ---------------- Fallback (–±–µ–∑ LLM) ----------------
def fallback_style_post(title: str, merged_text: str) -> str:
    # –∏–Ω—Ç—Ä–æ: –ø–µ—Ä–≤—ã–µ 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
    sents = re.split(r"(?<=[.!?‚Ä¶])\s+", merged_text)
    intro = " ".join(sents[:2]).strip()
    # 3‚Äì4 –ø—É–Ω–∫—Ç–∞: –±–µ—Ä—ë–º —Å–ª–µ–¥—É—é—â–∏–µ –Ω–∞—Å—ã—â–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏ —á–∞—Å—Ç–∏
    points = []
    for s in sents[2:]:
        s = s.strip()
        if 50 <= len(s) <= 220:
            # –ø–æ–¥—á—ë—Ä–∫–Ω–µ–º —á–∏—Å–ª–∞/—Ñ–∞–∫—Ç—ã
            s = re.sub(r"\b(\d[\d\s.,%]*\d|\d+)\b", r"<b>\1</b>", s)
            # –Ω–µ–º–Ω–æ–≥–æ –∫—É—Ä—Å–∏–≤–∞
            s = re.sub(r"\b([A-Za-z–ê-–Ø–∞-—è–Å—ë][A-Za-z–ê-–Ø–∞-—è–Å—ë\-]{6,})\b", r"<i>\1</i>", s, count=1)
            points.append(s)
        if len(points) >= 4:
            break
    if not intro:
        intro = merged_text[:220].rstrip() + "‚Ä¶"
    # –°–±–æ—Ä–∫–∞ —Å —ç–º–æ–¥–∑–∏-–Ω—É–º–µ—Ä–∞—Ü–∏–µ–π
    out_lines = [intro]
    emojis = ["1Ô∏è‚É£","2Ô∏è‚É£","3Ô∏è‚É£","4Ô∏è‚É£","5Ô∏è‚É£"]
    for i, pt in enumerate(points, 1):
        out_lines.append(f"{emojis[i-1]} {pt}")
    return "\n".join(out_lines).strip()

# ---------------- Telegram ----------------
def tg_send_photo(token: str, chat_id: str, caption_html: str, photo_url: Optional[str], thread_id: Optional[int] = None) -> int:
    url = f"{TELEGRAM_API_BASE}/bot{token}/sendPhoto"
    data = {"chat_id": chat_id, "caption": caption_html, "parse_mode": "HTML"}
    if thread_id is not None:
        data["message_thread_id"] = thread_id
    if photo_url:
        data["photo"] = photo_url
    r = requests.post(url, data=data, timeout=25)
    r.raise_for_status()
    return r.json()["result"]["message_id"]

def tg_copy(token: str, from_chat: str, msg_id: int, to_chat: str):
    url = f"{TELEGRAM_API_BASE}/bot{token}/copyMessage"
    data = {"from_chat_id": from_chat, "message_id": msg_id, "chat_id": to_chat}
    requests.post(url, data=data, timeout=20)

# ---------------- Main ----------------
def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--url", required=True)
    ap.add_argument("--item-selector", required=True)
    ap.add_argument("--limit", type=int, default=1)  # –æ–¥–Ω–∞ –ø–æ—Å–ª–µ–¥–Ω—è—è –Ω–æ–≤–æ—Å—Ç—å
    ap.add_argument("--base-url")
    ap.add_argument("--state", default=STATE_FILE)
    ap.add_argument("--with-photo", action="store_true")
    ap.add_argument("--thread-id", type=int)
    ap.add_argument("--copy-to-chat-id")
    args = ap.parse_args()

    token = os.getenv("TELEGRAM_BOT_TOKEN","").strip()
    chat_id = os.getenv("TELEGRAM_CHAT_ID","").strip()
    if not token or not chat_id:
        print("Set TELEGRAM_BOT_TOKEN and TELEGRAM_CHAT_ID", file=sys.stderr); sys.exit(2)

    thread_id = args.thread_id
    if thread_id is None:
        env_th = os.getenv("TELEGRAM_THREAD_ID","").strip()
        if env_th.isdigit(): thread_id = int(env_th)
    copy_chat = os.getenv("TELEGRAM_COPY_TO_CHAT_ID","").strip() or (args.copy_to_chat_id or "").strip()

    listing = fetch_html(args.url)
    links = extract_listing_links(listing, args.base_url, args.item_selector, args.limit)

    # state
    seen = set()
    if os.path.exists(args.state):
        try:
            seen = set(json.load(open(args.state,"r",encoding="utf-8")))
        except Exception:
            seen = set()

    posted = 0
    for link in links:
        if link in seen:
            continue

        item = parse_article(link, args.base_url)
        merged = join_for_llm(item.paras, target=900)

        body = llm_style_post(item.title, merged) or fallback_style_post(item.title, merged)
        # —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –∫–æ—Ä–æ—Ç–∫–∞—è –º—ã—Å–ª—å
        closing = "–ë–µ—Ä–µ–≥–∏—Ç–µ —Å–µ–±—è –Ω–∞ –¥–æ—Ä–æ–≥–µ –∏ –≤—ã–±–∏—Ä–∞–π—Ç–µ —Å —É–º–æ–º."

        # –∑–∞–≥–æ–ª–æ–≤–æ–∫ + —Ç–µ–ª–æ + –º—ã—Å–ª—å + –ø–æ–¥–ø–∏—Å—å
        emoji = choose_emoji(item.title, merged)
        caption = f"{emoji} <b>{html.escape(item.title)}</b>\n\n{body}\n\n{closing}\n\nüèéÔ∏è –†—É–ª–Å–∂–∫–∞ (https://t.me/drive_hedgehog)"
        # –æ–≥—Ä–∞–Ω–∏—á–∏–º –¥–ª–∏–Ω—É caption –¥–æ ~1024 –¥–ª—è —Ñ–æ—Ç–æ
        if len(caption) > 1024:
            caption = caption[:1000].rstrip() + "‚Ä¶\n\nüèéÔ∏è –†—É–ª–Å–∂–∫–∞ (https://t.me/drive_hedgehog)"

        msg_id = tg_send_photo(token, chat_id, caption, item.image if args.with_photo else None, thread_id)
        if copy_chat:
            tg_copy(token, chat_id, msg_id, copy_chat)

        seen.add(link)
        with open(args.state,"w",encoding="utf-8") as f:
            json.dump(sorted(list(seen)), f, ensure_ascii=False, indent=2)

        posted += 1
        time.sleep(1.0)

    print(f"Done. Posted {posted} item(s).")

if __name__ == "__main__":
    main()
