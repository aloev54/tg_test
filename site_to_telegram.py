#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
site_to_telegram.py ‚Äî –†—É–ª–Å–∂–∫–∞-—Å—Ç–∞–π–ª (LLM + –ª–∏–º–∏—Ç 1024 —Å–∏–º–≤–æ–ª–∞)

–§–æ—Ä–º–∞—Ç –ø–æ—Å—Ç–∞:
üöó **–ó–∞–≥–æ–ª–æ–≤–æ–∫**
–ò–Ω—Ç—Ä–∏–≥—É—é—â–µ–µ –≤—Å—Ç—É–ø–ª–µ–Ω–∏–µ (1‚Äì2 —Å—Ç—Ä–æ–∫–∏).
1Ô∏è‚É£ ... 2Ô∏è‚É£ ... 3Ô∏è‚É£ ...
–ö–æ—Ä–æ—Ç–∫–∞—è —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –º—ã—Å–ª—å/—Å–æ–≤–µ—Ç.
üèéÔ∏è –†—É–ª–Å–∂–∫–∞ (https://t.me/drive_hedgehog)

‚Äî –±–µ–∑ —Å—Å—ã–ª–æ–∫ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫
‚Äî —Ç–æ–ª—å–∫–æ <b> –∏ <i> –≤ HTML
‚Äî caption —Å—Ç—Ä–æ–≥–æ <= 1024 —Å–∏–º–≤–æ–ª–æ–≤ (–Ω–∏–∫–∞–∫–∏—Ö –æ–±—Ä–µ–∑–∞–Ω–∏–π —Ç—Ä–æ–µ—Ç–æ—á–∏–µ–º)
"""

import argparse, html, json, os, re, sys, time
from dataclasses import dataclass
from typing import List, Optional
from urllib.parse import urljoin

import requests
from bs4 import BeautifulSoup

DEFAULT_UA = "Mozilla/5.0 (compatible; rul-ezhka/2.0)"
TELEGRAM_API_BASE = "https://api.telegram.org"
STATE_FILE = "autonews_seen_nb.json"

ARTICLE_SELECTORS = [
    "article","[itemprop='articleBody']",".article__body",".js-mediator-article",".article",
]
DROP_SELECTORS = [
    "script","style","noscript",
    "[class*='advert']","[class*='ad-']","[class*='ad_']","[id*='ad']",
    "[class*='banner']","[class*='promo']",
    "[class*='subscribe']","[class*='subscription']",
    "[class*='breadcrumbs']","[class*='share']","[class*='social']",
    "[class*='tags']","[class*='related']","[class*='widget']",
    "figure figcaption",".photo-credit",".copyright",
]
DROP_PHRASES = [
    "—Ä–µ–∫–ª–∞–º–∞","–ø–æ–¥–ø–∏—Å","—á–∏—Ç–∞–π—Ç–µ —Ç–∞–∫–∂–µ","—Å–º–æ—Ç—Ä–∏—Ç–µ —Ç–∞–∫–∂–µ","–Ω–∞—à —Ç–µ–ª–µ–≥—Ä–∞–º",
    "–ø—Ä–æ–º–æ–∫–æ–¥","–ø–æ–¥—Ä–æ–±–Ω–µ–µ","—Ä–µ–∫–ª–∞–º",
]

EMOJI_MAP = [
    (["–¥—Ç–ø","–∞–≤–∞—Ä","—Å—Ç–æ–ª–∫–Ω–æ–≤"],"üö®"),
    (["—à—Ç—Ä–∞—Ñ","–Ω–∞–ª–æ–≥","–ø–æ—à–ª–∏–Ω","—É—Ç–∏–ª—å—Å–±–æ—Ä"],"üí∏"),
    (["—ç–ª–µ–∫—Ç—Ä–æ","ev","–±–∞—Ç–∞—Ä","–∑–∞—Ä—è–¥"],"‚ö°"),
    (["–±–µ–Ω–∑–∏–Ω","–¥–∏–∑–µ–ª","—Ç–æ–ø–ª–∏–≤"],"‚õΩ"),
    (["—Ç—Ä–∞—Å—Å","–¥–æ—Ä–æ–≥","—Ä–µ–º–æ–Ω—Ç","–º–æ—Å—Ç"],"üõ£Ô∏è"),
    (["–≥–æ–Ω–∫","—Å–ø–æ—Ä—Ç","—Ä–∞–ª–ª–∏","—Ç—Ä–µ–∫"],"üèÅ"),
]

@dataclass
class Item:
    title: str
    url: str
    image: Optional[str]
    paras: List[str]

# ---------------- Helpers ----------------
def fetch_html(url:str)->str:
    r=requests.get(url,headers={"User-Agent":DEFAULT_UA},timeout=25)
    r.raise_for_status()
    return r.text

def normalize_title(title:str)->str:
    t=title.strip()
    # —Å—Ä–µ–∑–∞–µ–º —Ö–≤–æ—Å—Ç—ã –≤—Ä–æ–¥–µ ¬´‚Äî Autonews¬ª, ¬´| Autonews¬ª, ¬´–ì–ª–∞–≤–Ω–æ–µ :: Autonews¬ª
    patterns=[
        r"\s*[-‚Äì‚Äî|:]{1,3}\s*(–ì–ª–∞–≤–Ω–æ–µ\s*)?::?\s*Autonews(?:\.ru)?\s*$",
        r"\s*[-‚Äì‚Äî|:]{1,3}\s*Autonews(?:\.ru)?\s*$",
        r"\s*\|\s*(–ì–ª–∞–≤–Ω–æ–µ|–ù–æ–≤–æ—Å—Ç–∏)\s*$",
        r"\s*::\s*(–ì–ª–∞–≤–Ω–æ–µ|–ù–æ–≤–æ—Å—Ç–∏)\s*$",
    ]
    for p in patterns:
        t=re.sub(p,"",t,flags=re.IGNORECASE)
    t=re.split(r"\s[-‚Äì‚Äî|:]{1,3}\s",t)[0].strip() or t
    return t

def extract_listing_links(html_text:str,base_url:Optional[str],selector:str,limit:int)->List[str]:
    soup=BeautifulSoup(html_text,"html.parser")
    nodes=soup.select(selector)[:limit]
    out=[]
    for n in nodes:
        a=n if n.name=="a" else n.find("a")
        if a and a.get("href"):
            href=urljoin(base_url,a["href"]) if base_url else a["href"]
            if href not in out:
                out.append(href)
    return out

def is_junk(t:str)->bool:
    lt=t.lower()
    if len(lt)<40: return True
    return any(p in lt for p in DROP_PHRASES)

def parse_article(url:str,base_url:Optional[str])->Item:
    soup=BeautifulSoup(fetch_html(url),"html.parser")

    # title
    t=soup.find("meta",property="og:title")
    title=t["content"].strip() if t and t.get("content") else (soup.title.string.strip() if soup.title else url)
    title=normalize_title(title)

    # image
    im=soup.find("meta",property="og:image")
    image=im["content"].strip() if im and im.get("content") else None
    if image and base_url:
        image=urljoin(base_url,image)

    # body root
    root=None
    for sel in ARTICLE_SELECTORS:
        node=soup.select_one(sel)
        if node:
            root=node;break
    if not root: root=soup

    # drop junk nodes (—É—Å—Ç–æ–π—á–∏–≤–æ –∫ –æ—à–∏–±–∫–∞–º —Å–µ–ª–µ–∫—Ç–æ—Ä–∞)
    for sel in DROP_SELECTORS:
        try:
            for node in root.select(sel):
                node.decompose()
        except Exception:
            continue

    paras=[]
    for p in root.find_all("p"):
        txt=re.sub(r"\s+"," ",p.get_text(" ",strip=True))
        if txt and not is_junk(txt):
            paras.append(txt)

    if not paras:
        d=soup.find("meta",property="og:description")
        if d and d.get("content"):
            paras=[d["content"].strip()]

    return Item(title=title,url=url,image=image,paras=paras[:12])

def choose_emoji(title:str,text:str)->str:
    s=(title+" "+text).lower()
    for keys,e in EMOJI_MAP:
        if any(k in s for k in keys):
            return e
    return "üöó"

def join_text(paras:List[str],limit:int=900)->str:
    out,cur=[],0
    for p in paras:
        if cur+len(p)>limit: break
        out.append(p);cur+=len(p)+1
        if len(out)>=6: break
    return " ".join(out)

# ---------------- LLM ----------------
def llm_style_post(title:str,text:str)->Optional[str]:
    api=os.getenv("OPENAI_API_KEY","").strip()
    if not api:
        return None
    import json,urllib.request as urlreq
    sys_prompt = (
    "–°–æ–∑–¥–∞–π –∫–æ—Ä–æ—Ç–∫–∏–π –ø–æ—Å—Ç (–¥–æ 1024 —Å–∏–º–≤–æ–ª–æ–≤) –¥–ª—è Telegram-–∫–∞–Ω–∞–ª–∞ –æ –º–∞—à–∏–Ω–∞—Ö. "
    "–ü–∏—à–∏ –∂–∏–≤–æ –∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ ‚Äî –∫–∞–∫ –∞–≤—Ç–æ–ª—é–±–∏—Ç–µ–ª—å, –∫–æ—Ç–æ—Ä—ã–π –¥–µ–ª–∏—Ç—Å—è –≤–ø–µ—á–∞—Ç–ª–µ–Ω–∏—è–º–∏. "
    "–ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –Ω—É–º–µ—Ä–∞—Ü–∏—é. –ù–∞—á–Ω–∏ —Å —è—Ä–∫–æ–π —Ñ—Ä–∞–∑—ã, –ø–æ—Ç–æ–º —Ä–∞—Å—Å–∫–∞–∂–∏ 2‚Äì3 —Ñ–∞–∫—Ç–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å —ç–º–æ—Ü–∏–µ–π, "
    "–∏ –∑–∞–∫–æ–Ω—á–∏ –ª—ë–≥–∫–∏–º —Å–æ–≤–µ—Ç–æ–º –∏–ª–∏ –≤—ã–≤–æ–¥–æ–º. "
    "–í—ã–¥–µ–ª—è–π <b>–∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã</b> –∏ <i>–∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ –¥–µ—Ç–∞–ª–∏</i>. "
    "–ù–µ –≤—Å—Ç–∞–≤–ª—è–π —Å—Å—ã–ª–∫–∏, –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–π –∑–∞–≥–æ–ª–æ–≤–æ–∫, –Ω–µ –ø—Ä–µ–≤—ã—à–∞–π 1024 —Å–∏–º–≤–æ–ª–∞."
    )
    payload={
        "model":"gpt-4o-mini",
        "temperature":0.35,
        "messages":[
            {"role":"system","content":sys_prompt},
            {"role":"user","content":f"–ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}\n\n–¢–µ–∫—Å—Ç –¥–ª—è –æ—Å–Ω–æ–≤—ã:\n{text}"}
        ]
    }
    req=urlreq.Request(
        "https://api.openai.com/v1/chat/completions",
        data=json.dumps(payload).encode("utf-8"),
        headers={"Authorization":f"Bearer {api}","Content-Type":"application/json"},
        method="POST",
    )
    try:
        with urlreq.urlopen(req,timeout=30) as resp:
            d=json.loads(resp.read().decode("utf-8"))
        t=d["choices"][0]["message"]["content"].strip().replace("\r","")
        # —Ä–∞–∑—Ä–µ—à–∞–µ–º —Ç–æ–ª—å–∫–æ <b>/<i>
        t=html.escape(t).replace("&lt;b&gt;","<b>").replace("&lt;/b&gt;","</b>").replace("&lt;i&gt;","<i>").replace("&lt;/i&gt;","</i>")
        return t[:1024]
    except Exception:
        return None

# ---------------- Fallback ----------------
def fallback_style_post(title:str,text:str)->str:
    # –∏–Ω—Ç—Ä–æ: 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
    sents=re.split(r"(?<=[.!?‚Ä¶])\s+",text)
    intro=" ".join(sents[:2]).strip()
    # 3‚Äì4 –ø—É–Ω–∫—Ç–∞
    pts=sents[2:6]
    emojis=["1Ô∏è‚É£","2Ô∏è‚É£","3Ô∏è‚É£","4Ô∏è‚É£"]
    body=[]
    for i in range(min(len(pts),4)):
        p=re.sub(r"(\d+)",r"<b>\1</b>",pts[i])  # —á–∏—Å–ª–∞ –∂–∏—Ä–Ω—ã–º
        body.append(emojis[i]+" "+p.strip())
    out = intro + ("\n" if intro and body else "") + "\n".join(body)
    return out[:1024]

# ---------------- Telegram ----------------
def tg_send_photo(token:str,chat_id:str,caption_html:str,photo_url:Optional[str],thread_id:Optional[int]=None)->int:
    data={"chat_id":chat_id,"caption":caption_html,"parse_mode":"HTML"}
    if thread_id is not None: data["message_thread_id"]=thread_id
    if photo_url: data["photo"]=photo_url
    r=requests.post(f"{TELEGRAM_API_BASE}/bot{token}/sendPhoto",data=data,timeout=30)
    r.raise_for_status()
    return r.json()["result"]["message_id"]

def tg_copy(token:str,from_chat_id:str,message_id:int,to_chat_id:str)->None:
    requests.post(f"{TELEGRAM_API_BASE}/bot{token}/copyMessage",
                  data={"from_chat_id":from_chat_id,"message_id":message_id,"chat_id":to_chat_id},
                  timeout=20)

# ---------------- Main ----------------
def main():
    ap=argparse.ArgumentParser()
    ap.add_argument("--url",required=True)
    ap.add_argument("--item-selector",required=True)
    ap.add_argument("--limit",type=int,default=1)  # –æ–¥–Ω–∞ –ø–æ—Å–ª–µ–¥–Ω—è—è
    ap.add_argument("--base-url")
    ap.add_argument("--state",default=STATE_FILE)
    ap.add_argument("--with-photo",action="store_true")
    ap.add_argument("--thread-id",type=int)
    ap.add_argument("--copy-to-chat-id")
    a=ap.parse_args()

    token=os.getenv("TELEGRAM_BOT_TOKEN","").strip()
    chat=os.getenv("TELEGRAM_CHAT_ID","").strip()
    if not token or not chat:
        sys.exit("Need TELEGRAM_BOT_TOKEN and TELEGRAM_CHAT_ID")

    # –±–µ–∑–æ–ø–∞—Å–Ω–æ —á–∏—Ç–∞–µ–º thread_id
    env_th=os.getenv("TELEGRAM_THREAD_ID","").strip()
    if a.thread_id is not None:
        th=a.thread_id
    elif env_th.isdigit():
        th=int(env_th)
    else:
        th=None

    copy=os.getenv("TELEGRAM_COPY_TO_CHAT_ID","").strip() or (a.copy_to_chat_id or "").strip()

    # state
    seen=set()
    if os.path.exists(a.state):
        try:
            with open(a.state,"r",encoding="utf-8") as f:
                seen=set(json.load(f))
        except Exception:
            seen=set()

    # —Å–ø–∏—Å–æ–∫ —Å—Å—ã–ª–æ–∫
    listing=fetch_html(a.url)
    links=extract_listing_links(listing,a.base_url,a.item_selector,a.limit)

    for link in links:
        if link in seen: continue
        item=parse_article(link,a.base_url)
        merged=join_text(item.paras,limit=900)

        body=llm_style_post(item.title,merged) or fallback_style_post(item.title,merged)

        # —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –º—ã—Å–ª—å
        closing="–ë–µ—Ä–µ–≥–∏—Ç–µ —Å–µ–±—è –Ω–∞ –¥–æ—Ä–æ–≥–µ –∏ –≤—ã–±–∏—Ä–∞–π—Ç–µ —Å —É–º–æ–º."

        # —Ñ–∏–Ω–∞–ª—å–Ω—ã–π caption (—Å—Ç—Ä–æ–≥–æ <=1024)
        emoji=choose_emoji(item.title,merged)
        cap=f"{emoji} <b>{html.escape(item.title)}</b>\n\n{body}\n\n{closing}\n\nüèéÔ∏è –†—É–ª–Å–∂–∫–∞ (https://t.me/drive_hedgehog)"
        cap=cap[:1024]

        msg_id=tg_send_photo(token,chat,cap,item.image if a.with_photo else None,th)
        if copy:
            tg_copy(token,chat,msg_id,copy)

        seen.add(link)
        with open(a.state,"w",encoding="utf-8") as f:
            json.dump(sorted(list(seen)),f,ensure_ascii=False,indent=2)

        time.sleep(1.0)

    print("Done.")

if __name__=="__main__":
    main()
